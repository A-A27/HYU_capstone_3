{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1C9N1Yzzh+JvlkZ9Zy/BJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-A27/HYU_capstone_3/blob/main/Pytesseract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxUCUwS1Nvu4"
      },
      "outputs": [],
      "source": [
        "# 이미지 불러오기\n",
        "from imutils.perspective import four_point_transform\n",
        "import matplotlib.pyplot as plt\n",
        "import pytesseract\n",
        "import imutils\n",
        "import cv2\n",
        "import re\n",
        "import requests\n",
        "import numpy as np\n",
        "def plt_imshow(title='image', img=None, figsize=(8 ,5)):\n",
        "    plt.figure(figsize=figsize)\n",
        " \n",
        "    if type(img) == list:\n",
        "        if type(title) == list:\n",
        "            titles = title\n",
        "        else:\n",
        "            titles = []\n",
        " \n",
        "            for i in range(len(img)):\n",
        "                titles.append(title)\n",
        " \n",
        "        for i in range(len(img)):\n",
        "            if len(img[i].shape) <= 2:\n",
        "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_GRAY2RGB)\n",
        "            else:\n",
        "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
        " \n",
        "            plt.subplot(1, len(img), i + 1), plt.imshow(rgbImg)\n",
        "            plt.title(titles[i])\n",
        "            plt.xticks([]), plt.yticks([])\n",
        " \n",
        "        plt.show()\n",
        "    else:\n",
        "        if len(img.shape) < 3:\n",
        "            rgbImg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "        plt.imshow(rgbImg)\n",
        "        plt.title(title)\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "        plt.show()\n",
        "url = 'https://user-images.githubusercontent.com/69428232/148330274-237d9b23-4a79-4416-8ef1-bb7b2b52edc4.jpg'\n",
        " \n",
        "image_nparray = np.asarray(bytearray(requests.get(url).content), dtype=np.uint8)\n",
        "org_image = cv2.imdecode(image_nparray, cv2.IMREAD_COLOR) \n",
        " \n",
        "plt_imshow(\"orignal image\", org_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 모서리 찾기\n",
        "image = org_image.copy()\n",
        "image = imutils.resize(image, width=500)\n",
        "ratio = org_image.shape[1] / float(image.shape[1])\n",
        " \n",
        "# 이미지를 grayscale로 변환하고 blur를 적용\n",
        "# 모서리를 찾기위한 이미지 연산\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5,), 0)\n",
        "edged = cv2.Canny(blurred, 75, 200)\n",
        " \n",
        "plt_imshow(['gray', 'blurred', 'edged'], [gray, blurred, edged])"
      ],
      "metadata": {
        "id": "i6LOA5BBNxRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 모서리 인식한 것 표시\n",
        "# contours를 찾아 크기순으로 정렬\n",
        "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
        " \n",
        "receiptCnt = None\n",
        " \n",
        "# 정렬된 contours를 반복문으로 수행하며 4개의 꼭지점을 갖는 도형을 검출\n",
        "for c in cnts:\n",
        "\tperi = cv2.arcLength(c, True)\n",
        "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
        " \n",
        "\t# contours가 크기순으로 정렬되어 있기때문에 제일 첫번째 사각형을 영수증 영역으로 판단하고 break\n",
        "\tif len(approx) == 4:\n",
        "\t\treceiptCnt = approx\n",
        "\t\tbreak\n",
        " \n",
        " \n",
        "# 만약 추출한 윤곽이 없을 경우 오류\n",
        "if receiptCnt is None:\n",
        "\traise Exception((\"Could not find receipt outline.\"))\n",
        "    \n",
        "output = image.copy()\n",
        "cv2.drawContours(output, [receiptCnt], -1, (0, 255, 0), 2)\n",
        "plt_imshow(\"Receipt Outline\", output)"
      ],
      "metadata": {
        "id": "4QokDW_oNzW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 보정하여 이미지 텍스트 출력\n",
        "# 원본 이미지에 찾은 윤곽을 기준으로 이미지를 보정\n",
        "receipt = four_point_transform(org_image, receiptCnt.reshape(4, 2) * ratio)\n",
        "plt_imshow(\"Receipt Transform\", receipt)\n",
        "options = \"--psm 4\"\n",
        "text = pytesseract.image_to_string(cv2.cvtColor(receipt, cv2.COLOR_BGR2RGB), config=options)\n",
        " \n",
        "# OCR결과 출력\n",
        "print(\"[INFO] OCR결과:\")\n",
        "print(\"==================\")\n",
        "print(text)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "yNZIlT6vN1R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파파고 처럼 단어 단위로 끊어서 볼 수 있게 이미지 처리\n",
        "gray = cv2.cvtColor(receipt, cv2.COLOR_BGR2GRAY)\n",
        "(H, W) = gray.shape\n",
        " \n",
        "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 20))\n",
        "sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 21))\n",
        " \n",
        "gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
        "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)\n",
        " \n",
        "grad = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
        "grad = np.absolute(grad)\n",
        "(minVal, maxVal) = (np.min(grad), np.max(grad))\n",
        "grad = (grad - minVal) / (maxVal - minVal)\n",
        "grad = (grad * 255).astype(\"uint8\")\n",
        " \n",
        "grad = cv2.morphologyEx(grad, cv2.MORPH_CLOSE, rectKernel)\n",
        "thresh = cv2.threshold(grad, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        " \n",
        "close_thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)\n",
        "close_thresh = cv2.erode(close_thresh, None, iterations=2)\n",
        " \n",
        "plt_imshow([\"Original\", \"Blackhat\", \"Gradient\", \"Rect Close\", \"Square Close\"], [receipt, blackhat, grad, thresh, close_thresh], figsize=(16, 10))"
      ],
      "metadata": {
        "id": "N9WnM_JEN40I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 단어 단위로 끊은 거 보여주기\n",
        "from imutils.contours import sort_contours\n",
        "cnts = cv2.findContours(close_thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "cnts = sort_contours(cnts, method=\"top-to-bottom\")[0]\n",
        " \n",
        "roi_list = []\n",
        "roi_title_list = []\n",
        " \n",
        "margin = 20\n",
        "receipt_grouping = receipt.copy()\n",
        " \n",
        "for c in cnts:\n",
        "  (x, y, w, h) = cv2.boundingRect(c)\n",
        "  ar = w // float(h)\n",
        " \n",
        "  if ar > 3.0 and ar < 6.5 and (W/2) < x:\n",
        "    color = (0, 255, 0)\n",
        "    roi = receipt[y - margin:y + h + margin, x - margin:x + w + margin]\n",
        "    roi_list.append(roi)\n",
        "    roi_title_list.append(\"Roi_{}\".format(len(roi_list)))\n",
        "  else:\n",
        "    color = (0, 0, 255)\n",
        " \n",
        "  cv2.rectangle(receipt_grouping, (x - margin, y - margin), (x + w + margin, y + h + margin), color, 2)\n",
        "  cv2.putText(receipt_grouping, \"\".join(str(ar)), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.65, color, 2)\n",
        "  \n",
        "  plt_imshow([\"Grouping Image\"], [receipt_grouping], figsize=(16, 10))"
      ],
      "metadata": {
        "id": "doBcxGzlN75h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 단위로 읽은 이미지에서 값 추출하기\n",
        "plt_imshow(roi_title_list, roi_list, figsize=(16, 10))\n",
        " \n",
        "for roi in roi_list:\n",
        "  gray_roi= cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "  threshold_roi = cv2.threshold(gray_roi, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "  roi_text = pytesseract.image_to_string(threshold_roi)\n",
        "  print(roi_text)"
      ],
      "metadata": {
        "id": "7B6jqQ3rN_Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mergeResize(img, row=300, col=200):\n",
        "    IMG_COL = col #66\n",
        " \n",
        "    # row값에 따른 col값 변경\n",
        "    IMG_COL = int((row * IMG_COL)/row)\n",
        " \n",
        "    IMG_ROW = row\n",
        "    border_v = 0\n",
        "    border_h = 0\n",
        " \n",
        "    if (IMG_COL / IMG_ROW) >= (img.shape[0] / img.shape[1]):\n",
        "        border_v = int((((IMG_COL / IMG_ROW) * img.shape[1]) - img.shape[0]) / 2)\n",
        "    else:\n",
        "        border_h = int((((IMG_ROW / IMG_COL) * img.shape[0]) - img.shape[1]) / 2)\n",
        "    img = cv2.copyMakeBorder(img, top=border_v, bottom=border_v, left=0, right=border_h + border_h, borderType=cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
        "    img = cv2.resize(img, (IMG_ROW, IMG_COL))\n",
        "    return img\n",
        "    \n",
        "for idx, roi in enumerate(roi_list):\n",
        "  if idx == 0:\n",
        "    mergeImg = mergeResize(roi)\n",
        "  else:\n",
        "    cropImg = mergeResize(roi)\n",
        "    mergeImg = np.concatenate((mergeImg, cropImg), axis=0)\n",
        "    \n",
        "threshold_mergeImg = cv2.threshold(mergeImg, 150, 255, cv2.THRESH_BINARY)[1]\n",
        "plt_imshow([\"Merge Image\"], [threshold_mergeImg])\n",
        "merge_Img_text = pytesseract.image_to_string(threshold_mergeImg)\n",
        "print(merge_Img_text)"
      ],
      "metadata": {
        "id": "-sGBjuyXN_eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qEbCOkvoOCCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}