{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwECqQfBHHpyP3QzAt97vp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-A27/HYU_capstone_3/blob/mediapipe/Mediapipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvTpxgWaCcMg"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import keyboard\n",
        "import time\n",
        "\n",
        "max_num_hands = 1\n",
        "gesture = {\n",
        "    0:'a', 1:'b', 2:'c',3:'d',4:'e',5:'f',6:'g',7:'h',\n",
        "    8:'i',9:'j',10:'k',11:'l',12:'m',13:'n',14:'o',\n",
        "    15:'p',16:'q',17:'r',18:'s',19:'t',20:'u',21:'v',\n",
        "    22:'w',23:'x',24:'y',25:'z',26:'spacing',27:'clear'\n",
        "}\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "hands = mp_hands.Hands(\n",
        "    max_num_hands = max_num_hands,\n",
        "    min_detection_confidence = 0.5,\n",
        "    min_tracking_confidence = 0.5)\n",
        "\n",
        "f = open('test.txt', 'w')\n",
        "\n",
        "file = np.genfromtxt('dataSet.txt', delimiter = ',')\n",
        "angleFile = file[:,:-1]\n",
        "labelFile = file[:,-1]\n",
        "angle = angleFile.astype(np.float32)\n",
        "label = lanelFile.astype(np.float32)\n",
        "knn = cv2.ml.KNearest_create()\n",
        "knn.train(angle, cv2.ml.ROW_SAMPLE, label)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "startTime = time.time()\n",
        "prev_index = 0\n",
        "sentence = ''\n",
        "recognizeDelay = 1\n",
        "while True:\n",
        "    ret,img = cap.read()\n",
        "    if not ret:\n",
        "        continue\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    result = hands.process(imgRGB)\n",
        "    \n",
        "    if result.multi_hand_landmarks is not None:\n",
        "        for res in result.multi_hand_landmarks:\n",
        "            joint = np.zeros((21,3))\n",
        "            for j, lm in enumerate(res.landmark):\n",
        "                joint[j] = [lm.x, lm.y, lm.z]\n",
        "            v1 = joint[[0, 1, 2, 3, 0, 5, 6, 7, 0, 9,10,11, 0,13,14,15, 0,17,18,19],:]\n",
        "            v2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
        "            \n",
        "            v = v2 - v1\n",
        "            v = v / np.linalg.norm(v, axis=1)[:,np.newaxis]\n",
        "            compareV1 = v[[0, 1, 2, 4, 5, 6, 7, 8, 9,10,12,13,14,16,17],:]\n",
        "            compareV2 = v[[1, 2, 3, 5, 6, 7, 9,10,11,13,14,15,17,18,19],:]\n",
        "            angle = np.arccos(np.einsum('nt, nt->n',compareV1, compareV2))\n",
        "            \n",
        "            angle = np.degrees(angle)\n",
        "            if keyboard.is_pressed('a'): #a를 누를 시 현재 데이터(angle)가 txt 파일에 저장됨\n",
        "                for num in angle:\n",
        "                    num = round(num, 6)\n",
        "                    f.write(str(num))\n",
        "                    f.write(',')\n",
        "                f.write(\"27.000000\") #데이터를 저장할 gesture의 label 번호\n",
        "                f.wirte('\\n')\n",
        "                print(\"next\")\n",
        "            data = np.array([angle], dtype = np.float32)\n",
        "            ret, result, neighbors, dist = knn.findNearest(data,3)\n",
        "            index = int(results[0][0])\n",
        "            if index in gesture.keys():\n",
        "                if index != prev_index:\n",
        "                    startTime = time.time()\n",
        "                    prev_index = index\n",
        "                else:\n",
        "                    if time.Time() - startTime > recognizeDelay:\n",
        "                        if index == 26:\n",
        "                            sentence += ' '\n",
        "                        elif index == 27:\n",
        "                            sentence = ''\n",
        "                        else:\n",
        "                            sentence += gesture[index]\n",
        "                        startTime = time.Time()\n",
        "                        \n",
        "                cv2.putText(img, gesture[index].upper(),(int(res.landmark[0].x * img.shape[1] - 10),\n",
        "                                                        int(res.landmark[0].y * img.shape[0] + 40)), cv2.FONT_HERSHEY_SIMPLEX, 1, color = (255,255,255),3)\n",
        "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
        "        cv2.putText(img, sentence, (20,440), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255),3)\n",
        "        \n",
        "        cv2.imshow('HandTracking', img)\n",
        "        cv2.waitKey(1)\n",
        "        if keyboard.is_pressed('b'): #b를 누를 시 프로그램 종료\n",
        "            break\n",
        "f.close();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "mpHands = mp.solutions.hands\n",
        "my_hands = mpHands.Hands()\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "def dist(x1,y1,x2,y2):\n",
        "    return math.sqrt(math.pow(x1-x2,2)) + math.sqrt(math.pow(y1-y2,2))\n",
        "\n",
        "compareIndex = [[18,4],[6,8],[10,12],[14,16],[18,20]]\n",
        "open = [False,False,False,False,False]\n",
        "gesture = [[True,True,True,True,True,\"Get Start!\"], # 캡쳐 부분 발견\n",
        "            [False,True,False,False,False,\"Line\"], # 캡쳐할 부분 밑줄 \n",
        "            [False,False,False,False,False,\"End\"]] # 캡쳐 종료\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    h,w,c = img.shape\n",
        "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    results = my_hands.process(imgRGB)\n",
        "    if results.multi_hand_landmarks:\n",
        "        for handLms in results.multi_hand_landmarks:\n",
        "            for i in range(0,5):\n",
        "                open[i] = dist(handLms.landmark[0].x,handLms.landmark[0].y,handLms.landmark[compareIndex[i][0]].x,handLms.landmark[compareIndex[i][0]].y) < dist(handLms.landmark[0].x,handLms.landmark[0].y,handLms.landmark[compareIndex[i][1]].x, handLms.landmark[compareIndex[i][1]].y)\n",
        "            print(open)\n",
        "            text_x = (handLms.landmark[0].x * w)\n",
        "            text_y = (handLms.landmark[0].y * h)\n",
        "            for i in range(0,len(gesture)):\n",
        "                flag = True\n",
        "                for j in range(0,5):\n",
        "                    if(gesture[i][j] != open[j]):\n",
        "                        flag = False\n",
        "                if(flag == True):\n",
        "                    cv2.putText(img,gesture[i][5],(round(text_x)-50,round(text_y)-250),cv2.FONT_HERSHEY_PLAIN,4,(0,0,0),4)\n",
        "            mpDraw.draw_landmarks(img,handLms,mpHands.HAND_CONNECTIONS)\n",
        "    cv2.imshow(\"HandTracking\",img)\n",
        "    cv2.waitKey()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vLecOGTEX0jU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}